import streamlit as st
import io
import json
import zipfile
import google.generativeai as genai

# API ì„¤ì •
genai.configure(api_key="AIzaSyCsYx7NOvpm-5MQey_Rhc5IVK6WmYE92fY")
model = genai.GenerativeModel("gemini-1.5-flash")

st.title("ğŸ“ ZIP ì—…ë¡œë“œ ê¸°ë°˜ ë…¼ë¬¸ ë¶„ì„ ì‹œìŠ¤í…œ")

# ZIP íŒŒì¼ ì—…ë¡œë“œ ìœ„ì ¯
uploaded_zip = st.file_uploader(
    "ë…¼ë¬¸ JSON íŒŒì¼ë“¤ì´ ë“¤ì–´ìˆëŠ” ZIP íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”:",
    type=["zip"]
)

question = st.text_input("AIì—ê²Œ ë¬¼ì–´ë³¼ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”:")

ask = st.button("ì§ˆë¬¸í•˜ê¸°")

if uploaded_zip is not None and question and ask:
    try:
        # ZIP íŒŒì¼ì„ ë©”ëª¨ë¦¬ì—ì„œ ì—´ê¸°
        with zipfile.ZipFile(io.BytesIO(uploaded_zip.read())) as z:
            context_list = []
            # ZIP ë‚´ë¶€ì˜ ëª¨ë“  íŒŒì¼ì„ ìˆœíšŒí•˜ë©° .jsonë§Œ ì²˜ë¦¬
            for name in z.namelist():
                if name.endswith(".json"):
                    with z.open(name) as f:
                        data = json.load(f)
                        sections = data.get("packages", {}) \
                                        .get("gpt", {}) \
                                        .get("sections", {})
                        title = sections.get("title", "")
                        abstract = sections.get("abstract", "")
                        method = sections.get("methodology", "")
                        result = sections.get("results", "")
                        context_list.append(
                            f"ğŸ“„ ì œëª©: {title}\n"
                            f"[ì´ˆë¡]\n{abstract}\n"
                            f"[ë°©ë²•ë¡ ]\n{method}\n"
                            f"[ê²°ê³¼]\n{result}\n"
                        )

        if not context_list:
            st.warning("ZIP íŒŒì¼ ì•ˆì— .json ë…¼ë¬¸ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        else:
            full_context = "\n\n---\n\n".join(context_list)
            prompt = f"""
ë‹¤ìŒì€ ì—¬ëŸ¬ ë…¼ë¬¸ì—ì„œ ì¶”ì¶œí•œ í•µì‹¬ ë‚´ìš©ì…ë‹ˆë‹¤. ì´ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ì•„ë˜ ì§ˆë¬¸ì— ë‹µí•´ì£¼ì„¸ìš”.

{full_context}

[ì§ˆë¬¸]
{question}
"""
            response = model.generate_content(prompt)
            st.subheader("ğŸ§  AIì˜ ì‘ë‹µ:")
            st.write(response.text)

    except Exception as e:
        st.error(f"ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
